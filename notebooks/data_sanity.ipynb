{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ecb02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sbi_particle_physics.objects.model import Model\n",
    "from sbi_particle_physics.objects.normalizer import Normalizer\n",
    "from sbi_particle_physics.managers.plotter import Plotter\n",
    "from sbi_particle_physics.managers.backup import Backup\n",
    "from sbi_particle_physics.config import DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882594e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_files = 10\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b758df",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = Backup.detect_files(DATA_DIR / \"data_2\")[:max_files]\n",
    "raw_data, raw_parameters, _ = Backup.load_data(files, device)\n",
    "n_samples = raw_data.shape[0]\n",
    "n_points = raw_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc0ff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Raw data\")\n",
    "print(raw_data.shape)\n",
    "print(raw_data[0,:10])\n",
    "unique_points, counts = torch.unique(\n",
    "    raw_data[0],\n",
    "    dim=0,\n",
    "    return_counts=True\n",
    ")\n",
    "print(\"#unique points\", unique_points.shape[0])\n",
    "\n",
    "print(\"\\nRaw parameters\")\n",
    "print(raw_parameters.shape)\n",
    "print(raw_parameters[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce5770",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer.create_normalizer(device, raw_data)\n",
    "data = normalizer.normalize_data(raw_data)\n",
    "parameters = normalizer.normalize_parameters(raw_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2d72f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotter.plot_a_sample(data[0], parameters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152b247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse statistique : moyennes et écarts-types pour chaque observable\n",
    "# Sélectionner quelques échantillons avec différentes valeurs de C_9\n",
    "\n",
    "# Trier par valeur de C_9\n",
    "sorted_indices = torch.argsort(raw_parameters.squeeze())\n",
    "n_compare = 5  # Nombre d'échantillons à comparer\n",
    "\n",
    "# Sélectionner des échantillons espacés (min, 25%, 50%, 75%, max)\n",
    "indices_to_compare = sorted_indices[torch.linspace(0, len(sorted_indices)-1, n_compare).long()]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPARAISON DES STATISTIQUES POUR DIFFÉRENTES VALEURS DE C_9\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "observable_names = [\"q²\", \"cos(θ_l)\", \"cos(θ_d)\", \"φ\"]\n",
    "\n",
    "for idx in indices_to_compare:\n",
    "    sample = raw_data[idx]\n",
    "    param = raw_parameters[idx]\n",
    "    \n",
    "    print(f\"\\n{'─' * 80}\")\n",
    "    print(f\"C_9 = {param.item():.4f}\")\n",
    "    print(f\"{'─' * 80}\")\n",
    "    print(f\"{'Observable':<15} {'Mean':<15} {'Std':<15} {'Min':<15} {'Max':<15}\")\n",
    "    print(f\"{'─' * 80}\")\n",
    "    \n",
    "    for i, obs_name in enumerate(observable_names):\n",
    "        obs_data = sample[:, i]\n",
    "        print(f\"{obs_name:<15} {obs_data.mean():.4f}{'':<10} \"\n",
    "              f\"{obs_data.std():.4f}{'':<10} \"\n",
    "              f\"{obs_data.min():.4f}{'':<10} \"\n",
    "              f\"{obs_data.max():.4f}{'':<10}\")\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"RÉSUMÉ : Vérification de la variabilité entre échantillons\")\n",
    "print(f\"{'=' * 80}\")\n",
    "\n",
    "# Calculer les moyennes pour tous les échantillons\n",
    "all_means = raw_data.mean(dim=1)  # [n_samples, 4]\n",
    "\n",
    "for i, obs_name in enumerate(observable_names):\n",
    "    means_for_obs = all_means[:, i]\n",
    "    print(f\"\\n{obs_name}:\")\n",
    "    print(f\"  - Moyenne des moyennes : {means_for_obs.mean():.4f}\")\n",
    "    print(f\"  - Écart-type des moyennes : {means_for_obs.std():.4f}\")\n",
    "    print(f\"  - Min des moyennes : {means_for_obs.min():.4f}\")\n",
    "    print(f\"  - Max des moyennes : {means_for_obs.max():.4f}\")\n",
    "    print(f\"  => Variabilité = {means_for_obs.std():.4f} (devrait être > 0 si C_9 a un effet)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48797efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation : comparer les distributions pour différentes valeurs de C_9\n",
    "print(\"\\nGénération des graphiques de comparaison...\")\n",
    "Plotter.compare_distributions(raw_data, raw_parameters, n_samples_to_plot=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72651c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de corrélation : vérifier si C_9 influence les distributions\n",
    "# Calculer la corrélation entre C_9 et les moyennes de chaque observable\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CORRÉLATION ENTRE C_9 ET LES OBSERVABLES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calculer les moyennes et écarts-types pour tous les échantillons\n",
    "all_means = raw_data.mean(dim=1)  # [n_samples, 4]\n",
    "all_stds = raw_data.std(dim=1)    # [n_samples, 4]\n",
    "\n",
    "c9_values = raw_parameters.squeeze().cpu().numpy()\n",
    "\n",
    "print(\"\\nCorrélation entre C_9 et la MOYENNE de chaque observable:\")\n",
    "print(f\"{'Observable':<15} {'Corrélation':<15} {'Interprétation':<30}\")\n",
    "print(\"─\" * 80)\n",
    "\n",
    "for i, obs_name in enumerate(observable_names):\n",
    "    means = all_means[:, i].cpu().numpy()\n",
    "    correlation = np.corrcoef(c9_values, means)[0, 1]\n",
    "    \n",
    "    if abs(correlation) > 0.5:\n",
    "        interpretation = \"FORTE dépendance\"\n",
    "    elif abs(correlation) > 0.2:\n",
    "        interpretation = \"Dépendance modérée\"\n",
    "    else:\n",
    "        interpretation = \"Faible dépendance\"\n",
    "    \n",
    "    print(f\"{obs_name:<15} {correlation:>+.4f}{'':<10} {interpretation:<30}\")\n",
    "\n",
    "print(\"\\nCorrélation entre C_9 et l'ÉCART-TYPE de chaque observable:\")\n",
    "print(f\"{'Observable':<15} {'Corrélation':<15} {'Interprétation':<30}\")\n",
    "print(\"─\" * 80)\n",
    "\n",
    "for i, obs_name in enumerate(observable_names):\n",
    "    stds = all_stds[:, i].cpu().numpy()\n",
    "    correlation = np.corrcoef(c9_values, stds)[0, 1]\n",
    "    \n",
    "    if abs(correlation) > 0.5:\n",
    "        interpretation = \"FORTE dépendance\"\n",
    "    elif abs(correlation) > 0.2:\n",
    "        interpretation = \"Dépendance modérée\"\n",
    "    else:\n",
    "        interpretation = \"Faible dépendance\"\n",
    "    \n",
    "    print(f\"{obs_name:<15} {correlation:>+.4f}{'':<10} {interpretation:<30}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CONCLUSION:\")\n",
    "print(\"Si les corrélations sont proches de 0, C_9 n'a PAS d'effet sur les distributions.\")\n",
    "print(\"Si les corrélations sont significatives (> 0.2 en valeur absolue), C_9 INFLUENCE les distributions.\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlhep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
