{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a7782ad",
   "metadata": {},
   "source": [
    "#### Simulation Based Inference of the decay $B \\to K^* \\mu \\mu$ with respect to the Wilson coefficient $C_9$\n",
    "The observables of interest are $s = q^2$, $\\theta_l$, $\\theta_d$ and $\\phi$.  \n",
    "\n",
    "Notation in this notebook:  \n",
    "Everything (parameters and data) is normalized except the objects labeled as \"raw\".  \n",
    "\n",
    "### Part A: Useful objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb7765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import eos\n",
    "import sbi\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sbi.utils import BoxUniform\n",
    "from sbi.inference import NPE\n",
    "from sbi.analysis import pairplot\n",
    "from sbi.analysis import plot_summary\n",
    "from sbi.diagnostics import run_sbc\n",
    "from sbi.analysis.plot import sbc_rank_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce31b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulator\n",
    "class Simulator:\n",
    "    # the simulator deals with un-normalized data (raw)\n",
    "    def __init__(self, device, stride, pre_N, preruns, sbi_C9):\n",
    "        self.device = device\n",
    "        self.stride = stride\n",
    "        self.pre_N = pre_N\n",
    "        self.preruns = preruns\n",
    "        self.rng = sbi_C9.rng\n",
    "        self.point_dim = sbi_C9.point_dim\n",
    "        self.parameter_dim = sbi_C9.parameter_dim\n",
    "\n",
    "        self.eos_kinematics = eos.Kinematics({\n",
    "            's':             2.0,   's_min':             1,       's_max' :            8.0,\n",
    "            'cos(theta_l)^LHCb':  0.0,  'cos(theta_l)^LHCb_min': -1.0,      'cos(theta_l)^LHCb_max': +1.0,\n",
    "            'cos(theta_k)^LHCb':  0.0,  'cos(theta_k)^LHCb_min': -1.0,      'cos(theta_k)^LHCb_max': +1.0,\n",
    "            'phi^LHCb':           0.3,  'phi^LHCb_min':           -1.0*np.pi,      'phi^LHCb_max':           1.0 * np.pi,\n",
    "        })\n",
    "\n",
    "        self.eos_options = eos.Options({\n",
    "            'l': 'mu',\n",
    "            'q': 'd',\n",
    "            'model': 'WET',\n",
    "            'debug': 'false',\n",
    "            'logging': 'quiet',\n",
    "            'log-level': 'off',\n",
    "            \n",
    "        })\n",
    "\n",
    "        self.eos_parameters = eos.Parameters()\n",
    "        \n",
    "        self.distribution = eos.SignalPDF.make(\n",
    "            'B->K^*ll::d^4Gamma@LowRecoil',\n",
    "            self.eos_parameters, # arbitrary value\n",
    "            self.eos_kinematics,\n",
    "            self.eos_options\n",
    "        )\n",
    "\n",
    "    def to_tensor(self, x, dtype=torch.float32):\n",
    "        return torch.as_tensor(x, dtype=dtype, device=self.device)\n",
    "\n",
    "    def simulate_a_sample(self, raw_parameter, n_points):\n",
    "        self.set_eos_parameter(raw_parameter)\n",
    "        raw_sample, _ = self.distribution.sample_mcmc(\n",
    "            N=n_points,\n",
    "            stride=self.stride,\n",
    "            pre_N=self.pre_N,\n",
    "            preruns=self.preruns,\n",
    "            rng=self.rng\n",
    "        )\n",
    "        return self.to_tensor(raw_sample)\n",
    "\n",
    "    def simulate_samples(self, raw_parameters, n_points):\n",
    "        n_samples = raw_parameters.shape[0]\n",
    "        raw_data = torch.zeros((n_samples, n_points, self.point_dim), dtype=torch.float32, device=self.device)\n",
    "        for i, raw_parameter in enumerate(raw_parameters):\n",
    "            raw_data[i] = self.simulate_a_sample(raw_parameter, n_points)\n",
    "        return raw_data\n",
    "\n",
    "    def set_eos_parameter(self, raw_parameter):\n",
    "        self.eos_parameters.set(\"b->smumu::Re{c9}\", raw_parameter[0].item())\n",
    "        return self.eos_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da17cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizer\n",
    "class Normalizer:\n",
    "    def __init__(self, raw_data, raw_parameters):\n",
    "        self.data_mean = raw_data.mean(dim=(0,1)) # shape (point_dim) (on ne mélange pas q^2, phi,...)\n",
    "        self.data_std = raw_data.std(dim=(0,1))\n",
    "        self.parameters_mean = raw_parameters.mean(dim=0) # shape (parameter_dim)\n",
    "        self.parameters_std = raw_parameters.std(dim=0)\n",
    "\n",
    "    def normalize_data(self, raw_x):\n",
    "        return (raw_x - self.data_mean) / self.data_std\n",
    "\n",
    "    def denormalize_data(self, x):\n",
    "        return x * self.data_std + self.data_mean\n",
    " \n",
    "    def normalize_parameters(self, raw_parameters):\n",
    "        return (raw_parameters - self.parameters_mean) / self.parameters_mean\n",
    "\n",
    "    def denormalize_parameters(self, parameters):\n",
    "        return parameters * self.parameters_std + self.parameters_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110da71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main entity\n",
    "class SBI_C9:\n",
    "    # Object containing everything we need\n",
    "    def __init__(self, device, seed, stop_after_epochs):\n",
    "        self.device = device\n",
    "        self.rng = np.random.mtrand.RandomState(seed)\n",
    "        self.stop_after_epochs = stop_after_epochs # souvent 20\n",
    "        self.prior = None\n",
    "        self.simulator = None\n",
    "        self.normalizer = None\n",
    "        # todo encoder\n",
    "        self.neural_network = None\n",
    "        self.posterior = None\n",
    "        self.point_dim = 4\n",
    "        self.parameter_dim = 1\n",
    "        self.data_labels = [\"$q^2$\", r\"$\\cos \\theta_l$\", r\"$\\cos \\theta_d$\", r\"$\\phi$\"]\n",
    "        self.parameters_labels = [\"$C_9$\"]\n",
    "\n",
    "    def to_tensor(self, x, dtype=torch.float32):\n",
    "        return torch.as_tensor(x, dtype=dtype, device=self.device)\n",
    "\n",
    "    def set_prior(self, raw_low, raw_high):\n",
    "        # low and high are raw since the normalization has not been done yet when this function is called\n",
    "        self.prior = BoxUniform(low=raw_low, high=raw_high, device=self.device)\n",
    "        self.neural_network = NPE(prior=self.prior, device=self.device, density_estimator=\"nsf\")\n",
    "\n",
    "    def set_simulator(self, simulator):\n",
    "        self.simulator = simulator\n",
    "\n",
    "    def set_normalizer(self, normalizer):\n",
    "        self.normalizer = normalizer\n",
    "\n",
    "    def draw_raw_parameters_from_prior(self, n_parameters):\n",
    "        return self.prior.sample((n_parameters,))\n",
    "    \n",
    "    def simulate_raw_data(self, n_samples, n_points): # used before creating the normalizer\n",
    "        raw_parameters = self.draw_raw_parameters_from_prior(n_samples)\n",
    "        return self.simulator.simulate_samples(raw_parameters, n_points), raw_parameters\n",
    "\n",
    "    def simulate_data(self, n_samples, n_points):\n",
    "        raw_data, raw_parameters = self.simulate_raw_data(n_samples, n_points)\n",
    "        return self.normalizer.normalize_data(raw_data), self.normalizer.normalize_parameters(raw_parameters)\n",
    "    \n",
    "    def simulate_data_with_parameters(self, parameters, n_points):\n",
    "        raw_parameters = self.normalizer.denormalize_parameters(parameters)\n",
    "        raw_data = self.simulator.simulate_samples(raw_parameters, n_points)\n",
    "        return self.normalizer.normalize_data(raw_data)\n",
    "\n",
    "    def train(self, data, parameters):\n",
    "        self.neural_network.append_simulations(parameters, data) # self.neural_network = ... ?\n",
    "        self.neural_network.train(stop_after_epochs=self.stop_after_epochs)\n",
    "        self.posterior = self.neural_network.build_posterior(sample_with='mcmc')\n",
    "\n",
    "    # draw parameters from the posterior predicted for some observed sample\n",
    "    def draw_parameters_from_predicted_posterior(self, observed_sample, n_parameters):\n",
    "        return self.posterior.sample((n_parameters,), x=observed_sample)\n",
    "\n",
    "    # used to compare an observed sample with samples produced with parameters drawn from the posterior distribution predicted for the observed sample\n",
    "    def simulate_data_from_predicted_posterior(self, observed_sample, n_samples, n_points):\n",
    "        parameters = self.draw_parameters_from_predicted_posterior(observed_sample, n_samples)\n",
    "        return self.simulate_data_with_parameters(parameters, n_points), parameters\n",
    "    \n",
    "    def get_random_true_parameter(self, n_points):\n",
    "        raw_parameter = self.draw_raw_parameters_from_prior(1)\n",
    "        parameter = self.normalizer.normalize_parameters(raw_parameter)\n",
    "        data = self.simulate_data_with_parameters(parameter, n_points)\n",
    "        return parameter.squeeze(0), data.squeeze(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaab23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploter and Validator\n",
    "class Ploter_Validator:\n",
    "    # make cool plots and test the performance \n",
    "    axis_fontsize = 21 # companion object variables\n",
    "    legend_fontsize = 15\n",
    "    tick_fontsize = 15        \n",
    "\n",
    "    @staticmethod\n",
    "    def plot_a_sample_1D(sample, parameter, label):\n",
    "        fig, ax = plt.subplots(figsize=(7,4))\n",
    "        ax.hist(\n",
    "            sample,\n",
    "            bins=40, \n",
    "            color=\"blue\",\n",
    "            alpha=0.7,\n",
    "            label=f\"$C_9={parameter.item():.3f}$\"\n",
    "        )\n",
    "        ax.set_xlabel(label, fontsize=Ploter_Validator.axis_fontsize)\n",
    "        ax.tick_params(labelsize=Ploter_Validator.tick_fontsize)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend(fontsize=Ploter_Validator.legend_fontsize)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_a_sample(sbi_C9, sample, parameter):\n",
    "        for i,label in enumerate(sbi_C9.data_labels):\n",
    "            Ploter_Validator.plot_a_sample_1D(sample[:,i], parameter, label)\n",
    "\n",
    "    # plot train and validation loss during last training\n",
    "    @staticmethod\n",
    "    def plot_loss(neural_network):\n",
    "        _ = plot_summary(\n",
    "            neural_network,\n",
    "            tags=[\"training_loss\", \"validation_loss\"],\n",
    "            figsize=(10, 2),\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_a_posterior_parameter(sampled_parameters, label):\n",
    "        fig, ax = plt.subplots(figsize=(7,4))\n",
    "        ax.hist(\n",
    "            sampled_parameters,\n",
    "            bins=40,\n",
    "            density=True,\n",
    "            alpha=0.6,\n",
    "            color=\"green\",\n",
    "            label=\"posterior\"\n",
    "        )\n",
    "        ax.set_xlabel(label, fontsize=Ploter_Validator.axis_fontsize)\n",
    "        ax.tick_params(labelsize=Ploter_Validator.tick_fontsize)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend(fontsize=Ploter_Validator.legend_fontsize)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_a_posterior(sbi_C9, sampled_parameters):\n",
    "        for i,label in enumerate(sbi_C9.parameters_labels):\n",
    "            Ploter_Validator.plot_a_posterior_parameter(sampled_parameters[:,i], label)\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_similar_data_1D(observed_sample, similar_data, label):\n",
    "        fig, ax = plt.subplots(figsize=(7,4))\n",
    "        ax.hist(\n",
    "            observed_sample,\n",
    "            bins=40, \n",
    "            color=\"red\",\n",
    "            alpha=1,\n",
    "            label=f\"True data\",\n",
    "            density=True\n",
    "        )\n",
    "        for i in range(similar_data.shape[0]):\n",
    "             ax.hist(\n",
    "                similar_data[i],\n",
    "                bins=40, \n",
    "                alpha=0.3,\n",
    "                color=\"blue\",\n",
    "                density=True\n",
    "            )\n",
    "        ax.set_xlabel(label, fontsize=Ploter_Validator.axis_fontsize)\n",
    "        ax.tick_params(labelsize=Ploter_Validator.tick_fontsize)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend(fontsize=Ploter_Validator.legend_fontsize)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # plot data generated from parameters drawn from the posterior estimation associated with the observed sample\n",
    "    @staticmethod\n",
    "    def plot_similar_data(sbi_C9, observed_sample, n_samples, n_points):\n",
    "        similar_data, similar_parameters = sbi_C9.simulate_data_from_predicted_posterior(observed_sample[:,0], n_samples, n_points)\n",
    "        # todo attention il faudra enlever [:,0] une fois l'encodeur implémenté\n",
    "        print(\"similar shape\", similar_data.shape)\n",
    "        print(\"observed shape\", observed_sample.shape)\n",
    "        for i,label in enumerate(sbi_C9.data_labels):\n",
    "            Ploter_Validator.plot_similar_data_1D(observed_sample[:,i], similar_data[:,:,i], label)\n",
    "\n",
    "    @staticmethod\n",
    "    def do_sbc(sbi_c9):\n",
    "        pass# todo \n",
    "\n",
    "    # todo do ppc, hdi and more tests "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f3135f",
   "metadata": {},
   "source": [
    "### Part B: Actual inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a633ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Body\n",
    "n_samples = 10\n",
    "n_points = 100 # points per sample\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed = 1\n",
    "stop_after_epochs = 1\n",
    "sbi_C9 = SBI_C9(device, seed, stop_after_epochs)\n",
    "\n",
    "raw_low = sbi_C9.to_tensor([3])\n",
    "raw_high = sbi_C9.to_tensor([5])\n",
    "sbi_C9.set_prior(raw_low, raw_high)\n",
    "\n",
    "stride = 1\n",
    "pre_N = 200\n",
    "preruns = 1\n",
    "sbi_C9.set_simulator(Simulator(device, stride, pre_N, preruns, sbi_C9))\n",
    "\n",
    "raw_data, raw_parameters = sbi_C9.simulate_raw_data(n_samples, n_points)\n",
    "sbi_C9.set_normalizer(Normalizer(raw_data, raw_parameters))\n",
    "data = sbi_C9.normalizer.normalize_data(raw_data)\n",
    "parameters = sbi_C9.normalizer.normalize_parameters(raw_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7fb81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbi_C9.train(data[:,:,0], parameters) # pour l'instant une dimension de point (il faut fair encoder)\n",
    "Ploter_Validator.plot_loss(sbi_C9.neural_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02432e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ploter_Validator.plot_a_sample(sbi_C9,data[0], parameters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ffab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_parameter, observed_sample = sbi_C9.get_random_true_parameter(n_points)\n",
    "n_sampled_parameters = 1000\n",
    "sampled_parameters = sbi_C9.draw_parameters_from_predicted_posterior(observed_sample[:,0], n_sampled_parameters)\n",
    "Ploter_Validator.plot_a_posterior(sbi_C9, sampled_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960aa11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_similar = 5\n",
    "Ploter_Validator.plot_similar_data(sbi_C9, observed_sample, n_similar, n_points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlhep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
