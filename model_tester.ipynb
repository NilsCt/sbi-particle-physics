{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35f1da5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from model import Model\n",
    "from ploter import Ploter\n",
    "from backup_manager import BackupManager\n",
    "from validator import Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf44e363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from models/model1.pkl\n"
     ]
    }
   ],
   "source": [
    "model, device = BackupManager.load_model(\"models/model1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec3c70a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data185.pt\n",
      "(data: torch.Size([500, 1000, 4]), params: torch.Size([500, 1]))\n"
     ]
    }
   ],
   "source": [
    "n_points = 1000\n",
    "n_samples = 200\n",
    "x_raw, theta_raw, metadata = BackupManager.load_one_file(\"data/data185.pt\")\n",
    "x = model.normalizer.normalize_data(x_raw)\n",
    "theta = model.normalizer.normalize_parameters(theta_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58b6ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hep/nrc25/miniconda3/envs/mlhep/lib/python3.12/site-packages/sbi/diagnostics/sbc.py:83: UserWarning: Using non-batched sampling. Depending on the number of different xs ( 500) and the number of parallel workers 1, this might take a lot of time.\n",
      "  posterior_samples = get_posterior_samples_on_batch(\n",
      "Sampling 500 times (1000,) posterior samples.:   0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Validator.simulation_based_calibration(model, x[:200], theta[:200], 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75651587",
   "metadata": {},
   "outputs": [],
   "source": [
    "Validator.posterior_predictive_checks(model, x[0:1], n_samples, n_points) # normalement plutot 5000 que 500 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a28e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hep/nrc25/miniconda3/envs/mlhep/lib/python3.12/site-packages/sbi/diagnostics/sbc.py:83: UserWarning: Using non-batched sampling. Depending on the number of different xs ( 500) and the number of parallel workers 1, this might take a lot of time.\n",
      "  posterior_samples = get_posterior_samples_on_batch(\n",
      "Sampling 500 times (1000,) posterior samples.:   0%|          | 0/500 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mValidator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpected_coverage_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/sbi-particle-physics/validator.py:82\u001b[39m, in \u001b[36mValidator.expected_coverage_test\u001b[39m\u001b[34m(model, x, theta, num_posterior_samples)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexpected_coverage_test\u001b[39m(model, x, theta, num_posterior_samples):\n\u001b[32m     81\u001b[39m     \u001b[38;5;66;03m#x, theta = model.simulate_data(n_samples, n_points)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     ranks, dap_samples = \u001b[43mrun_sbc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mposterior\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduce_fns\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mposterior\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_posterior_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_posterior_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_batched_sampling\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# `True` can give speed-ups, but can cause memory issues.\u001b[39;49;00m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m     fig, ax = sbc_rank_plot(\n\u001b[32m     91\u001b[39m         ranks,\n\u001b[32m     92\u001b[39m         num_posterior_samples,\n\u001b[32m   (...)\u001b[39m\u001b[32m     95\u001b[39m         figsize=(\u001b[32m5\u001b[39m, \u001b[32m3\u001b[39m),\n\u001b[32m     96\u001b[39m     )\n\u001b[32m     97\u001b[39m     plt.show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/sbi/diagnostics/sbc.py:83\u001b[39m, in \u001b[36mrun_sbc\u001b[39m\u001b[34m(thetas, xs, posterior, num_posterior_samples, reduce_fns, num_workers, show_progress_bar, use_batched_sampling, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m     warnings.warn(\n\u001b[32m     76\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`sbc_batch_size` is deprecated and will be removed in future versions.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     77\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m Use `num_workers` instead.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     78\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m     79\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m     80\u001b[39m     )\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# Get posterior samples, batched or parallelized.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m posterior_samples = \u001b[43mget_posterior_samples_on_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposterior\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_posterior_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_batched_sampling\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_batched_sampling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# Take a random draw from each posterior to get data-averaged posterior samples.\u001b[39;00m\n\u001b[32m     93\u001b[39m dap_samples = posterior_samples[\u001b[32m0\u001b[39m, :, :]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/sbi/utils/diagnostics_utils.py:77\u001b[39m, in \u001b[36mget_posterior_samples_on_batch\u001b[39m\u001b[34m(xs, posterior, sample_shape, num_workers, show_progress_bar, use_batched_sampling)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Run in parallel with progress bar.\u001b[39;00m\n\u001b[32m     76\u001b[39m seeds = torch.randint(\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m**\u001b[32m32\u001b[39m, (num_xs,))\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m outputs = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturn_as\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgenerator\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_fun\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposterior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSampling \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum_xs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m times \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msample_shape\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m posterior samples.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, num_samples, dim_parameters)\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# Transpose to shape convention: (sample_shape, batch_size, dim_parameters)\u001b[39;00m\n\u001b[32m     89\u001b[39m posterior_samples = torch.stack(\n\u001b[32m     90\u001b[39m     outputs  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     91\u001b[39m ).permute(\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/sbi/utils/diagnostics_utils.py:65\u001b[39m, in \u001b[36mget_posterior_samples_on_batch.<locals>.sample_fun\u001b[39m\u001b[34m(posterior, sample_shape, x, seed)\u001b[39m\n\u001b[32m     63\u001b[39m     posterior.train()\n\u001b[32m     64\u001b[39m torch.manual_seed(seed)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mposterior\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bars\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/sbi/inference/posteriors/mcmc_posterior.py:346\u001b[39m, in \u001b[36mMCMCPosterior.sample\u001b[39m\u001b[34m(self, sample_shape, x, method, thin, warmup_steps, num_chains, init_strategy, init_strategy_parameters, init_strategy_num_candidates, mcmc_parameters, mcmc_method, sample_with, num_workers, mp_context, show_progress_bars)\u001b[39m\n\u001b[32m    343\u001b[39m init_strategy = _maybe_use_dict_entry(init_strategy, \u001b[33m\"\u001b[39m\u001b[33minit_strategy\u001b[39m\u001b[33m\"\u001b[39m, m_p)\n\u001b[32m    344\u001b[39m \u001b[38;5;28mself\u001b[39m.potential_ = \u001b[38;5;28mself\u001b[39m._prepare_potential(method)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m initial_params = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_initial_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_chains\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minit_strategy_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m num_samples = torch.Size(sample_shape).numel()\n\u001b[32m    355\u001b[39m track_gradients = method \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mhmc_pyro\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnuts_pyro\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhmc_pymc\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnuts_pymc\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/sbi/inference/posteriors/mcmc_posterior.py:659\u001b[39m, in \u001b[36mMCMCPosterior._get_initial_params\u001b[39m\u001b[34m(self, init_strategy, num_chains, num_workers, show_progress_bars, **kwargs)\u001b[39m\n\u001b[32m    655\u001b[39m     initial_params = torch.cat(initial_params)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    657\u001b[39m     initial_params = torch.cat(\n\u001b[32m    658\u001b[39m         [\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m             \u001b[43minit_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    660\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[32m    661\u001b[39m                 \u001b[38;5;28mrange\u001b[39m(num_chains),\n\u001b[32m    662\u001b[39m                 desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_chains\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m MCMC inits via \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minit_strategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    663\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstrategy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    664\u001b[39m                 disable=\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bars,\n\u001b[32m    665\u001b[39m             )\n\u001b[32m    666\u001b[39m         ]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    667\u001b[39m     )\n\u001b[32m    668\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m initial_params.shape[\u001b[32m0\u001b[39m] == num_chains, \u001b[33m\"\u001b[39m\u001b[33mInitial params shape mismatch.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    669\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m initial_params\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/sbi/inference/posteriors/mcmc_posterior.py:593\u001b[39m, in \u001b[36mMCMCPosterior._build_mcmc_init_fn.<locals>.<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    589\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m: sir_init(\n\u001b[32m    590\u001b[39m         proposal, potential_fn, transform=transform, **kwargs\n\u001b[32m    591\u001b[39m     )\n\u001b[32m    592\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m init_strategy == \u001b[33m\"\u001b[39m\u001b[33mresample\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m593\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mresample_given_potential_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproposal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpotential_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m init_strategy == \u001b[33m\"\u001b[39m\u001b[33mlatest_sample\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    597\u001b[39m     latest_sample = IterateParameters(\u001b[38;5;28mself\u001b[39m._mcmc_init_params, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/sbi/samplers/mcmc/init_strategy.py:101\u001b[39m, in \u001b[36mresample_given_potential_fn\u001b[39m\u001b[34m(proposal, potential_fn, transform, num_candidate_samples, num_batches, **kwargs)\u001b[39m\n\u001b[32m     99\u001b[39m     batch_draws = proposal.sample((num_candidate_samples,)).detach()\n\u001b[32m    100\u001b[39m     init_param_candidates.append(batch_draws)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     log_weights.append(\u001b[43mpotential_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_draws\u001b[49m\u001b[43m)\u001b[49m.detach())\n\u001b[32m    102\u001b[39m log_weights = torch.cat(log_weights)\n\u001b[32m    103\u001b[39m init_param_candidates = torch.cat(init_param_candidates)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/sbi/inference/potentials/posterior_based_potential.py:159\u001b[39m, in \u001b[36mPosteriorBasedPotential.__call__\u001b[39m\u001b[34m(self, theta, track_gradients)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x_batch_size == \u001b[32m1\u001b[39m:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# If a single `x` is passed (i.e. batchsize==1), we squeeze\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# the batch dimension of the log-prob with `.squeeze(dim=1)`.\u001b[39;00m\n\u001b[32m    155\u001b[39m     theta = reshape_to_sample_batch_event(\n\u001b[32m    156\u001b[39m         theta, event_shape=theta.shape[\u001b[32m1\u001b[39m:], leading_is_sample=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    157\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     posterior_log_prob = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mposterior_estimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m     posterior_log_prob = posterior_log_prob.squeeze(\u001b[32m1\u001b[39m)\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# If multiple `x` are passed, we return the log-probs for each (x,theta)\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# pair, and do not squeeze the batch dimension.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/sbi/neural_nets/estimators/nflows_flow.py:109\u001b[39m, in \u001b[36mNFlowsFlow.log_prob\u001b[39m\u001b[34m(self, input, condition)\u001b[39m\n\u001b[32m    106\u001b[39m ones_for_event_dims = (\u001b[32m1\u001b[39m,) * condition_event_dims  \u001b[38;5;66;03m# Tuple of 1s, e.g. (1, 1, 1)\u001b[39;00m\n\u001b[32m    107\u001b[39m condition = condition.repeat(input_sample_dim, *ones_for_event_dims)\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m log_probs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m log_probs.reshape((input_sample_dim, input_batch_dim))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/nflows/distributions/base.py:40\u001b[39m, in \u001b[36mDistribution.log_prob\u001b[39m\u001b[34m(self, inputs, context)\u001b[39m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inputs.shape[\u001b[32m0\u001b[39m] != context.shape[\u001b[32m0\u001b[39m]:\n\u001b[32m     37\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     38\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mNumber of input items must be equal to number of context items.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     39\u001b[39m         )\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/nflows/flows/base.py:39\u001b[39m, in \u001b[36mFlow._log_prob\u001b[39m\u001b[34m(self, inputs, context)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_log_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, context):\n\u001b[32m     38\u001b[39m     embedded_context = \u001b[38;5;28mself\u001b[39m._embedding_net(context)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     noise, logabsdet = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedded_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     log_prob = \u001b[38;5;28mself\u001b[39m._distribution.log_prob(noise, context=embedded_context)\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m log_prob + logabsdet\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/nflows/transforms/base.py:56\u001b[39m, in \u001b[36mCompositeTransform.forward\u001b[39m\u001b[34m(self, inputs, context)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     55\u001b[39m     funcs = \u001b[38;5;28mself\u001b[39m._transforms\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cascade\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuncs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/nflows/transforms/base.py:50\u001b[39m, in \u001b[36mCompositeTransform._cascade\u001b[39m\u001b[34m(inputs, funcs, context)\u001b[39m\n\u001b[32m     48\u001b[39m total_logabsdet = inputs.new_zeros(batch_size)\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m funcs:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     outputs, logabsdet = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     total_logabsdet += logabsdet\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs, total_logabsdet\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/nflows/transforms/coupling.py:84\u001b[39m, in \u001b[36mCouplingTransform.forward\u001b[39m\u001b[34m(self, inputs, context)\u001b[39m\n\u001b[32m     81\u001b[39m transform_split = inputs[:, \u001b[38;5;28mself\u001b[39m.transform_features, ...]\n\u001b[32m     83\u001b[39m transform_params = \u001b[38;5;28mself\u001b[39m.transform_net(identity_split, context)\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m transform_split, logabsdet = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_coupling_transform_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform_params\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unconditional_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     89\u001b[39m     identity_split, logabsdet_identity = \u001b[38;5;28mself\u001b[39m.unconditional_transform(\n\u001b[32m     90\u001b[39m         identity_split, context\n\u001b[32m     91\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/nflows/transforms/coupling.py:194\u001b[39m, in \u001b[36mPiecewiseCouplingTransform._coupling_transform_forward\u001b[39m\u001b[34m(self, inputs, transform_params)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_coupling_transform_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, transform_params):\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_coupling_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/nflows/transforms/coupling.py:213\u001b[39m, in \u001b[36mPiecewiseCouplingTransform._coupling_transform\u001b[39m\u001b[34m(self, inputs, transform_params, inverse)\u001b[39m\n\u001b[32m    209\u001b[39m     transform_params = transform_params.reshape(b, d, -\u001b[32m1\u001b[39m)\n\u001b[32m    211\u001b[39m outputs, logabsdet = \u001b[38;5;28mself\u001b[39m._piecewise_cdf(inputs, transform_params, inverse)\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs, \u001b[43mtorchutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum_except_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogabsdet\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlhep/lib/python3.12/site-packages/nflows/utils/torchutils.py:19\u001b[39m, in \u001b[36msum_except_batch\u001b[39m\u001b[34m(x, num_batch_dims)\u001b[39m\n\u001b[32m     15\u001b[39m     x_ = x_.reshape(-\u001b[32m1\u001b[39m)\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x_\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msum_except_batch\u001b[39m(x, num_batch_dims=\u001b[32m1\u001b[39m):\n\u001b[32m     20\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Sums all elements of `x` except for the first `num_batch_dims` dimensions.\"\"\"\u001b[39;00m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check.is_nonnegative_int(num_batch_dims):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "Validator.expected_coverage_test(model, x[:200], theta[:200], 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b86cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hep/nrc25/miniconda3/envs/mlhep/lib/python3.12/site-packages/sbi/diagnostics/tarp.py:75: UserWarning: Using non-batched sampling. Depending on the number of different xs ( 500) and the number of parallel workers 1, this might take a lot of time.\n",
      "  posterior_samples = get_posterior_samples_on_batch(\n",
      "Sampling 500 times (1000,) posterior samples.:   0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Validator.tarp_test(model, x[:200], theta[:200], 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397e41fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_o = x[1].unsqueeze(0)\n",
    "x_train = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d02ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Validator.misspecification_test(model, x_train, x_o) # normalement 1000 plutot que 500 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72b82d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Validator.misspecification_test_mmd(model, x_train, x_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68216fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Validator.lc2st_test(model, 10000, n_points, x_o)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlhep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
